---
title: Geologic Layer Development
description: Description of how geologic layers are developed
author: Oak Ridges Moraine Groundwater Program
date: 2022-11-22
output: html_document
---

# Introduction
Construction of aquifer and aquitard layers geometry has been one of the most challenging tasks of the ORMGP. this is an ongoing process whereby the geologic layers are updated as new data and conceptual understanding is available. The picking of geologic surfaces at borehole locations is a fundamental step in this process, however, to fully represent the complexity of the aquifer/aquitard system, geologic picks were supplemented with information obtained from subtle hydrogeologic indicators (such as well screen placement and well depth) as well as from expert intuition and geologic conceptual understanding of the sedimentological processes. This information was integrated into the model construction process using 3-D polylines to constrain the interpolation processes.

Database integration, data visualization, geologic layer picking and geostatistical analysis functions provided are required to review and interpret the large amounts of borehole data (discussed further below). The result is a hydrostratigraphic model that honours the borehole and well data and encapsulates the conceptual understanding of the processes that formed the Oak Ridges Moraine.

# Background




![*Figure 1: ORMGP Geologic Layer Development*](https://raw.githubusercontent.com/OWRC/GeoLayers/main/images/sharpe01.png)

![*Figure 2: ORMGP Geologic Layer Development*](https://raw.githubusercontent.com/OWRC/GeoLayers/main/images/sharpe02.png)

# Data Correction and Data Biases
Ontario Ministry of Environment driller’s logs form the majority of the borehole information in the database. The accuracy and reliability of individual wells in this data set is sometimes questionable, however, the logs provide a significant amount of useful subsurface information. Care was taken to screen the data visually and correct for obvious or known errors, thereby minimizing the intrinsic biases in the driller’s logs.

ome of the location and elevation errors in the MOE’s database were addressed through field validation (using GPS) of over 5,000 of the wells which had not previously been located (Beatty and Associates 2003). Borehole elevations were compared against, and adjusted to the high resolution DEM (10 m cell size) to minimize elevation errors. Highly erroneous or unreliable wells (MOE quality code greater than 6) were excluded from the analysis.

Water well records in the western Oak Ridges Moraine were compared against detailed core logging from geotechnical, hydrogeological and sedimentologically-logged boreholes (Sharpe et al., 2002). Logan et al. (2001) showed the value of using these high-quality records to “train’ the well records (e.g. Logan et al., 2001). Thus, higher quality “golden spike” wells and seismic picks were used extensively during layer refinement. The high quality “golden spike” wells, seismic picks, and outcrop data (as well as any other higher quality data) were identified (and given greater weight) using a variety of qualitative measures. Well ownership was also examined and any wells drilled by a consultant or for a municipality were assumed to be of higher quality and were given more weight in the interpretation. Frequently, wells with poorer or better quality information could be readily identified by visually comparing clusters of wells on cross section (e.g. poorer wells would have a single geological description through the entire depth of the well).

A standardized scheme to re-code driller’s log descriptions was developed by three GSC geologists for the Oak Ridges Moraine area (Russell et al., 1998). Re-coded lithologic information helped identify drillers’ tendencies in reporting data but could not be relied upon without referring to the high-quality data. A significant bias was the use of the term “clay” by the water well drillers. In reality, analysis suggested that reported “clay“ material was more likely to be silt or fine sand. Similarly, drillers rarely use the term till but use terms such as “hardpan” or “hard” or report occurrences of “clay gravel”. Re-coded lithologic log information was displayed on cross section during interpretation and picking, however, presentation of the original (un-coded) raw MOE lithologic descriptions was still considered essential to the identification of unit boundaries and key indicator patterns.

Other percieved biases and patterns were identified during the geological surface refinement process. As most drillers are hired simply to “find water”, they frequently stop drilling as soon as they encounter a significant aquifer zone. Since tapping into the top few metres of a significant aquifer is all that is necessary to meet the needs of most domestic well owners, very little of the permeable aquifer material is sampled and documented within the driller’s logs. As a result, the majority of driller’s logs are typically a record of aquitard materials, with only the bottom-most screened sand or gravel unit representative of aquifer material. Despite these biases, highly significant patterns were identified within the logs, as discussed in the following sections.

# Data Visualization and Analysis Software 
VIEWLOG was the borehole analysis/GIS software used for all data visualization, synthesis and interpretation tasks in this study. The software provides an integrated set of GIS mapping functions (including 3-D gridding and contouring), dynamic cross section generationing, real-time 3-D fly-throughs, and borehole data display, editing and picking functions, as shown in Figure D131. The software directly connects directly to the relational database containing the borehole logs, well construction, and water level data. This allows the user to dynamically query and filter the visual presentation based on database criteria.

Despite the fact that the data is highly three-dimensional in nature, most interpretation was performed on cross sections. Real-time 3-D viewing provides a more qualitative view of the data, however, for detailed and accurate layer picking, cross sections provide a more suitable framework. The use of the software’s dynamic cross sections, which can be easily shifted back and forth through the dataset, was another important feature of the layer refinement process. At any point during the interpretation, the vertical exaggeration could be adjusted and the borehole offset changed to add or remove boreholes from the section. The cross sections could also be dynamically sliced through one or more geologic models, allowing units from the stratigraphic and hydrostratigraphic models to be easily compared. Finally, to further assist in the layer refinement, the surficial geology was also included on all sections as a color-coded band (using standard lithology colors) immediately below the ground surface. 

Considerable effort was spent optimizing the presentation of the borehole data on cross section. The software permits the display of any number of columns of lithology (raw codes, GSC recoding, etc.) and hydraulic information (well screen, static water level, etc.) at each well location. Lithology symbol patterns and colors were chosen to fully represent the range of material codes and allow for the identification of subtle patterns and correlations (Figure D132). A pop-up window containing the well details, in tabular or graphical form, was also available during the interpretation process. It was determined that the most effective display on cross section was to use all three columns of MOE geological descriptions (Mat 1, Mat 2, Mat 3), hydrogeologic indicators such as well screen interval in a fourth column, and the GSC recoded lithology in a fifth column. 

The software’s 3--D polyline drawing functions were used to capture the expert’s intuition during the interpretation process. Polylines are simply lines of contact separating different hydrostratigraphic or geologic units. Ensuring the continuity of channel and valley systems was necessary to correctly simulate the flow of water through these features. While well picking formed the majority of the interpretation task, 3--D polylines were used to constrain and control the surface generation process (Figure D133). Polylines were added either perpendicular or parallel to the axis of a channel or valley feature. Each polyline was assigned to a hydrostratigraphic unit, and the individual vertex points in that polyline were then included (along with the well picks) in the gridding process for that particular unit. For example, the drainage pattern in bedrock valley systems was created by adding polylines down the inferred thalweg cross section. The truncation and pinch out of layers at the edges of the tunnel channels was defined using polylines perpendicular to the axis of the channel feature. Plan view manual contouring was also integrated as necessary. 

Figure D133 presents a sample cross section and shows how 3-D polylines were used to constrain tunnel channel geometry. The thin black lines in the figure that generally follow the unit boundaries are the constraint polylines. These constraint lines, together with the borehole picks, produce the unit boundaries (final interpolated units are show as solid color filled zones). 

# Interpretation Methodology
Creation of the refined hydrostratigraphic surfaces involved an iterative process of interpretation, gridding and refinement. Complex structures and patterns emerged slowly, as time was spent viewing and interpreting the data. Group meetings were frequently held to review and discuss the emerging understanding of the system. 

Since hydrostratigraphic interpretation and refinement were occurring simultaneously, data management and database synchronization also turned out to be an important issue during the interpretation phases of the model refinement. Meetings provided an opportunity to coordinate data management and ensure consistency among the interpreters. 

Elements of the GSC’s rules-based approach to the generation of the stratigraphic surfaces (Logan et al., 2001) were incorporated into the hydrostratigraphic interpretation methodology. In particular, their conceptual approach to the handling of “push downs” was particularly useful. A push down condition exists when a borehole partially penetrates a geologic unit: the next lower unit must exist below the bottom of the partially penetrating well, but how far below is unknown. The main interpretive methodologies used were: i) cross-section picking; ii) an emphasis on 
hydrologic indicators; and iii) the use of 3--D constraint polylines. In summary, the following steps were used to generate the hydrostratigraphic surfaces: 

## Step 1: Picking and Pattern Identification
Hydrostratigraphic units were picked on thousands of dynamically generated cross sections through the Core Model area. Sections were viewed, at minimum, along every concession road, which are spaced approximately every 2 km. In more complex areas sections every 500 m were interpreted. Over 67,000 layer picks were made in boreholes along these sections. Key patterns in the drillers logs emerged during this process, and were highlighted using characteristic lithology symbols and colors. An important part of the display was the optimization of certain colours with specific MOE geological descriptors, allowing specific patterns in the material codes to be identified. Some of the important patterns include:
- Hardness: the terms “dense”, “hard”, and “packed” were used interchangeably by different drillers. Intervals with these terms were colour coded pink (Figure D132) on section. These descriptors appeared to be commonly applied to the Newmarket Aquitard unit. The bright pink colour was therefore used as a guide to identify this unit.
- Clay+ stones or Clay+ gravel: The combination of the clay and stones (or clay and gravel) also emerged as a reliable till indicator. In this case clay had to be the primary material and stones the secondary material. 
- Coarse material + Well Screen: Coarse grained material alone (i.e. sand) cannot always be assumed to be representative of a good aquifer. In many cases the sand might be quite silty. Sand, combined with a well screen, was considered much more likely to be representative of a good aquifer. 
- Well screen position: In many cases well screens are clustered at a particular depth position, suggesting a good aquifer zone. 
- Well material similarity and detail patterns: The visual comparison of materials from a group of wells could, in many cases, lead to a better and more reliable interpretation. The “noise” and variability in the individual well descriptions could be visually filtered to identify a formation 
contact. A related issue was the level of descriptive detail in an individual well. For example, wells with too few material codes or long sections of very simple descriptions were, in some cases, considered “suspect” (suggesting that the driller was not attentive to the geological changes that were present). 
- Silt + and lack of hard material code: The GSC suggested (Russell et al., 1998) that in many cases clay materials identified by drillers was, in actual fact, silt. However, where silt was described in the MOE logs, it was observed that there was a link between the location of these wells and the location of potential tunnel channels. This correlation, especially where the term “hard” as a material modifier was absent, led to a general interpretation that “silt“ was a potential indicator of tunnel channel sediments.

## Step 2: Addition of 3D Polyline Constraints
During the cross section interpretation, 3-D polylines were added to constrain the gridding process. These polylines ensured the continuity of geologic structures. Polylines were also used to help constrain “push down” conditions (described below). In total, over 12,000 polyline vertex points were defined.

Polylines were used to define both the base and the width of the bedrock valley systems. A combination of deep bedrock wells and deep “push-down” wells were used to initially define the position of the bedrock valley systems. The shape of the valley was then defined with additional polylines. With very limited data in the deep valley systems, particularly the main branch of the Laurentian River, some assumptions had to be made about the channel width and the slope of the valley walls. Modern analogs were reviewed, including the Niagara River (the Laurentian was suspected to be of a similar size and flow rate). Bronte Creek and 16 Mile Creek, which are relatively deeply incised into the Queenston Shale, and the Credit River were also considered. The primary question was whether the river would incise deeply in the soft shale, or would the river meander and undermine the valley walls, resulting in shallow, broad valley. Evidence for both conditions was found, and a basic valley width for the main channel was assumed to be approximately 4 km wide. Initially polylines were drawn along the thalweg of the valley. Several sets of parallel polylines were then drawn on both sides of the thalweg line and positioned at successively higher elevations to “shape” the valley to this 4 km wide feature. The resulting bedrock surface was checked and modified based on the actual well data. A recent seismic survey across the main channel near Schomberg suggests that the channel is at least this wide (CAMC, in preparation). The width of other tributaries was evaluated on a case by case basis and conformed to local available well data. Care was also taken to ensure that the tributaries also correctly connected into the main channel. 

North of the moraine, the high resolution DEM was used as an additional source of information when interpreting the tunnel channels. Constraint polylines were used to extend the surficial expression of the tunnel channels down into the geologic model, however with limited data, depth control was limited. In the case of the tunnel channels, interpretation lines perpendicular to the channel were drawn that truncated units (e.g. Newmarket Aquitard, Thorncliffe Aquifer, etc.) at the edges of the inferred channel. The depth of the channels (and the polylines that shape the valleys) was determined by looking for wells with geological intervals that were discontinuous with wells outside of channel areas. In addition, a coarse aquifer within the valley was also sought as an “anchor” that might indicate the coarse depositional phase that is typical at the base of the channel sediments.

In summary, polylines provide an important control over the gridding process, however they need to be used carefully and only where necessary. Verification of the layer geometry is ongoing, through both drilling and seismic surveys across the study area. With time, polyline constraints can be removed as hard data is collected and substituted. At present, however, polylines represent a key link between the conceptual model and numerical model.

## Step 3: Pushdown Check
Handling of “push down” conditions was particularly important to the interpretation of the bedrock surface because of the sparseness of the data and the potentially strong influence of the Laurentian River valley system. A “push down” condition occurs where a deep well, which does not encounter bedrock, indicates that the bedrock surface must be lower than the estimated interpolation level. The deep “push down” well does not actually encounter bedrock, however it proves that bedrock is some distance below the bottom of the borehole. The bedrock surface must be “pushed down” below the base of that well, even though the bedrock is not actually encountered in that well.

Deep “push-down” wells were used both before and after polyline drawing step. Both bedrock wells and deep push-down wells were reviewed to initially identify the bedrock valley thalweg positions. One the thalwegs were defined (as outlined above), additional push-down checks were performed to ensure that these deep indicator wells were fully integrated into the surface generation process.

Specific display techniques were used to help visualize the push-down conditions. Sediment boreholes (e.g. those that do not encounter bedrock) were plotted on plan view with a bottom-hole elevation represented by scaled and gradationally color coded symbols. This allowed deep push down holes to clearly appear as large, bright symbols. Bedrock valley thalwegs were then interpreted on plan view, and cross sections were generated along those thalwegs. Polylines were added to the thalweg cross sections to ensure that the bedrock surface correctly represented the decreasing elevation of the valley system.

Other push-down surface checks were performed in a manner similar to the GSC methodology (Logan et al., 2001). In general, the following steps were used:
- Bedrock picks were made at all wells that intercept bedrock 
- The initial bedrock surface was interpolated using all bedrock picks 
- The non-bedrock (sediment) wells were evaluated by plotting them on plan view with a bottom-hole elevation represented by scaled and gradationally color coded symbols, thus showing deep overburden wells as large, bright symbols. 
- Using the initially interpolated bedrock surface and the deep, brightly coloured, non-bedrock wells, bedrock valleys were identified and bedrock valley thalwegs were drawn on plan view. 
- Cross-sections were generated along the bedrock valley thalwegs and bedrock polylines were drawn on-section to represent the bedrock surface. The polylines were drawn to connect the bedrock picks and to ensure that the bedrock surface was beneath the deeper sediment wells. The lines were also drawn to ensure that the bedrock surface correctly represented the decreasing elevation of a fluvially eroded valley system. 
- The secondary bedrock surface was then interpolated using the bedrock picks at the bedrock wells and the vertex points of the bedrock surface polylines created along the bedrock valley thalwegs. 
- This surface was checked against the non-bedrock wells to see whether any of the non-bedrock wells intersected the secondary bedrock surface. 
- Where non-bedrock wells were deeper than the secondary bedrock surface the elevation of the well bottom was added as an additional bedrock point to “push down” the final bedrock surface. 
- Additional polylines were added on cross-sections parallel to the bedrock valley thalwegs to better “shape” the bedrock valleys. 
- The final bedrock surface was interpolated using all of the above: bedrock picks; polyline vertex points; and the deep non-bedrock wells that pushed down the bedrock surface. 

## Step 4: Variogram Analyses and Interpolation
Once the picking, polylines and push down analysis was complete the surfaces were generated using variogram analysis and kriging. Variogram analysis is discussed below. 

## Step 5: Rules-based Post Processing
Finally, the surfaces were crosschecked using a series of rules. The rules ensured, for example, that the interpolated layers did not cross. The rules were developed and applied in an order that reflected the distinctive characteristics of each hydrostratigraphic interface (i.e. unconformity, etc.) and the confidence and distinctiveness of the lithologic signature. For example, the ground surface was assigned the highest level of confidence, followed by the bedrock surface, top of the Newmarket Till, and then the remaining units. The following were some of the surface post processing rules:
- If Bedrock > Ground then Bedrock = Ground 
- If Newmarket > Ground then Newmarket = Ground 
- If Newmarket < Bedrock then Newmarket = Bedrock 
- If Thorncliffe > Newmarket then Throncliffe = Newmarket 
- If Thorncliffe < Bedrock then Thorncliffe = Bedrock 
- If Sunnybrook > Thorncliffe then Sunnybrook = Thorncliffe 
- Etc…

Other surface cross checks were included, including reconciliation with the surficial geology units. Note that the order the equations were processed was also important, as each surface check relied on the preceeding checks and constrants. The approach was not simply a top-down correction, for example constraining the Halton till was one of the last checks performed. Note that other model-layer specific checks were also performed, as outlined in Appendix D, Section 4.2.5.1.

# Conclusions
Layer picking is a complex and challenging task that requires a concerted effort to understand existing conceptual models and adapt and refine them as necessary. The model construction process is complicated by the low quality and conflicting information contained in the MOE well database. Good conceptual models are needed to guide the interpretation process, but actually representing the conceptual insight within the numerical model is a particular challenge.

It is important to point out that the hydrostratigraphic surfaces produced through this study are by no means perfect or complete, and will be in need of continual improvement into the future. Although every effort was made to ensure that the aquifer and aquitard layers developed under this project are consistent with the data, the area covered is simply too large to be able to go into detail everywhere. This concept of continual improvement is in keeping with the overall spirit of the YPDT groundwater management study.

From a flow modelling perspective, continuity and pinch-out of layers is more important than the precise elevation of the surfaces: the models respond to transmissivity changes, including both layer thickness and hydraulic conductivity.

The methodologies used in this project are consistent with those used in other large agencies, including the Alberta Geological Survey, South Florida Water Management District, USGS and Danish Geological Survey, to name only a few. The GSC is also using the same toolset for adapting and refining their stratigraphic surfaces.
